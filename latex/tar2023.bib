%%% ====================================================================
%%%  BibTeX-file{
%%%     author          = "David Rhead",
%%%     version         = "1.00",
%%%     date            = "17 Feb 1990",
%%%     time            = "17:00 GMT",
%%%     filename        = "test.bib",
%%%     address         = "Cripps Computing Centre,
%%%                        University of Nottingham,
%%%                        University Park,
%%%                        Nottingham,
%%%                        NG7 2RD,
%%%                        United Kingdom",
%%%     telephone       = "+44 602 484848 Ext 2670",
%%%     FAX             = "+44 602 588138",
%%%     checksum        = "05151 839 2908 25082",
%%%     email           = "David_Rhead at uk.ac.nott.vme (JANET)",
%%%     codetable       = "ISO/ASCII",
%%%     keywords        = "bibliography, citation, references",
%%%     supported       = "no",
%%%     docstring       = "This BibTeX database file contains entries
%%%                        designed for testing whether a BibTeX style
%%%                        file lays references out as recommended by
%%%                        certain authorities.  (Note, however, that
%%%                        the BS 1629 examples are from the 1976
%%%                        edition.  The file needs updating to use
%%%                        examples from the 1989 edition instead.)
%%%
%%%                        The checksum field above contains a CRC-16
%%%                        checksum as the first value, followed by the
%%%                        equivalent of the standard UNIX wc (word
%%%                        count) utility output of lines, words, and
%%%                        characters.  This is produced by Robert
%%%                        Solovay's checksum utility.",
%%%  }
%%% ====================================================================


%% @COMMENT{Some standard works describing conventions for citations
%%      and bibliographies}

@inproceedings{homma2016detecting,
  title={Detecting duplicate questions with deep learning},
  author={Homma, Yushi and Sy, Stuart and Yeh, Christopher},
  booktitle={Proceedings of the International Conference on Neural Information Processing Systems (NIPS},
  pages={25964--25975},
  year={2016}
}

@misc{dadashov2017quora,
  title={Quora question duplication},
  author={Dadashov, Elkhan and Sakshuwong, Sukolsak and Yu, Katherin},
  year={2017},
  publisher={Stanford University}
}

@misc{iyer2017first,
  title={First Quora Dataset Release: Question Pairs},
  author={Iyer, Shankar and Dandekar, Nikhil and Csernai, Korn√©l},
  year={2017},
  url = {\url{https://quoradata.quora.com/First-Quora-Dataset-Release-Question-Pairs}},
  note = {Accessed: 2024-06-06}
}

@inproceedings{reimers-2019-sentence-bert,
  title = "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks",
  author = "Reimers, Nils and Gurevych, Iryna",
  booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing",
  month = "11",
  year = "2019",
  publisher = "Association for Computational Linguistics",
  url = "https://arxiv.org/abs/1908.10084",
}

@inproceedings{bogdanova2015detecting,
  title={Detecting semantically equivalent questions in online user forums},
  author={Bogdanova, Dasha and dos Santos, Cicero and Barbosa, Luciano and Zadrozny, Bianca},
  booktitle={Proceedings of the nineteenth conference on computational natural language learning},
  pages={123--131},
  year={2015}
}

@inproceedings{prabowo2019duplicate,
  title={Duplicate question detection in question answer website using convolutional neural network},
  author={Prabowo, Damar Adi and Herwanto, Guntur Budi},
  booktitle={2019 5th International conference on science and technology (ICST)},
  volume={1},
  pages={1--6},
  year={2019},
  organization={IEEE}
}

@inproceedings{dey2016paraphrase,
  title={A paraphrase and semantic similarity detection system for user generated short-text content on microblogs},
  author={Dey, Kuntal and Shrivastava, Ritvik and Kaushik, Saroj},
  booktitle={Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers},
  pages={2880--2890},
  year={2016}
}

@article{imtiaz2020duplicate,
  title={Duplicate questions pair detection using siamese malstm},
  author={Imtiaz, Zainab and Umer, Muhammad and Ahmad, Muhammad and Ullah, Saleem and Choi, Gyu Sang and Mehmood, Arif},
  journal={IEEE Access},
  volume={8},
  pages={21932--21942},
  year={2020},
  publisher={IEEE}
}

@inproceedings{fradelos2023using,
  title={Using Siamese BiLSTM Models for Identifying Text Semantic Similarity},
  author={Fradelos, Georgios and Perikos, Isidoros and Hatzilygeroudis, Ioannis},
  booktitle={IFIP International Conference on Artificial Intelligence Applications and Innovations},
  pages={381--392},
  year={2023},
  organization={Springer}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@inproceedings{pennington2014glove,
  author = {Jeffrey Pennington and Richard Socher and Christopher D. Manning},
  booktitle = {Empirical Methods in Natural Language Processing (EMNLP)},
  title = {GloVe: Global Vectors for Word Representation},
  year = {2014},
  pages = {1532--1543},
  url = {http://www.aclweb.org/anthology/D14-1162},
}

@article{gkouti2024should,
  title={Should I try multiple optimizers when fine-tuning pre-trained Transformers for NLP tasks? Should I tune their hyperparameters?},
  author={Gkouti, Nefeli and Malakasiotis, Prodromos and Toumpis, Stavros and Androutsopoulos, Ion},
  journal={arXiv preprint arXiv:2402.06948},
  year={2024}
}

@article{sanh2019distilbert,
  title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},
  author={Sanh, Victor and Debut, Lysandre and Chaumond, Julien and Wolf, Thomas},
  journal={arXiv preprint arXiv:1910.01108},
  year={2019}
}

@article{liu2019roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}

@inproceedings{sun2019fine,
  title={How to fine-tune bert for text classification?},
  author={Sun, Chi and Qiu, Xipeng and Xu, Yige and Huang, Xuanjing},
  booktitle={Chinese computational linguistics: 18th China national conference, CCL 2019, Kunming, China, October 18--20, 2019, proceedings 18},
  pages={194--206},
  year={2019},
  organization={Springer}
}