{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marko/fer/taar/project/duplicate-question-identification/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import spacy\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80226</th>\n",
       "      <td>Why is email encryption important?</td>\n",
       "      <td>Why isn't email encrypted?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292700</th>\n",
       "      <td>How can I learn to focus on something?</td>\n",
       "      <td>How can I focus on something?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329203</th>\n",
       "      <td>Why is bluing agent used?</td>\n",
       "      <td>Why is bluing agent used to whiten the white c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142931</th>\n",
       "      <td>If I ask a question and then unfollow it, will...</td>\n",
       "      <td>If I ask a question anonymously, do I get cred...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314893</th>\n",
       "      <td>What type of economy does Greece have? How eff...</td>\n",
       "      <td>What type of government does Greece have? How ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                question1  \\\n",
       "80226                  Why is email encryption important?   \n",
       "292700             How can I learn to focus on something?   \n",
       "329203                          Why is bluing agent used?   \n",
       "142931  If I ask a question and then unfollow it, will...   \n",
       "314893  What type of economy does Greece have? How eff...   \n",
       "\n",
       "                                                question2  is_duplicate  \n",
       "80226                          Why isn't email encrypted?             0  \n",
       "292700                      How can I focus on something?             1  \n",
       "329203  Why is bluing agent used to whiten the white c...             1  \n",
       "142931  If I ask a question anonymously, do I get cred...             0  \n",
       "314893  What type of government does Greece have? How ...             0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/train.csv', dtype={'id': int, 'qid1': int, 'qid2': int, 'question1': str, 'question2': str, 'is_duplicate': int})\n",
    "data.drop(data.columns[[0, 1, 2]], axis=1, inplace=True)\n",
    "train_df, test_df = train_test_split(data, test_size=0.4)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from podium import Vocab, Field, LabelField\n",
    "from podium.datasets import TabularDataset\n",
    "from podium.vectorizers import GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Since the GPL-licensed package `unidecode` is not installed, using Python's `unicodedata` package which yields worse results.\n",
      "/Users/marko/fer/taar/project/duplicate-question-identification/.venv/lib/python3.9/site-packages/podium/vocab.py:514: UserWarning: Vocabulary is finalized already. This should be used only if multiple fields use same vocabulary.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from podium.preproc import TextCleanUp\n",
    "\n",
    "max_vocab_size = 10_000\n",
    "vocab = Vocab(max_size=max_vocab_size, min_freq=2)\n",
    "\n",
    "cleanup = TextCleanUp(remove_punct=True)\n",
    "\n",
    "def lowercase(raw: str):\n",
    "    return raw.lower()\n",
    "\n",
    "Q1 = Field(name='question1',\n",
    "           tokenizer='split',\n",
    "           numericalizer=vocab,\n",
    "           pretokenize_hooks=[cleanup, lowercase])\n",
    "Q2 = Field(name='question2',\n",
    "           tokenizer='split',\n",
    "           numericalizer=vocab,\n",
    "           pretokenize_hooks=[cleanup, lowercase])\n",
    "IS_DUPLICATE = LabelField(name='is_duplicate')\n",
    "\n",
    "fields = [\n",
    "    Q1,\n",
    "    Q2,\n",
    "    IS_DUPLICATE,\n",
    "]\n",
    "\n",
    "train = TabularDataset.from_pandas(train_df, fields)\n",
    "test = TabularDataset.from_pandas(test_df, fields)\n",
    "train.finalize_fields()\n",
    "\n",
    "glove = GloVe()\n",
    "# Load only the vectors of vocab words.\n",
    "embeddings = glove.load_vocab(vocab)\n",
    "\n",
    "# Generate padded batch.\n",
    "train_batch = train.batch(add_padding=True)\n",
    "test_batch = test.batch(add_padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch.question1 = train_batch.question1.astype(int)\n",
    "train_batch.question2 = train_batch.question2.astype(int)\n",
    "test_batch.question1 = test_batch.question1.astype(int)\n",
    "test_batch.question2 = test_batch.question2.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    \"\"\"\n",
    "    Receives two 2D numpy arrays and calculates cosine similarity across the second axis.\n",
    "    For examples, if `a` and `b` have shape (32, 10), the resulting array should have shape (32,).\n",
    "    \n",
    "    Returns:\n",
    "        1D numpy array with cosine similarities\n",
    "    \"\"\"\n",
    "    res = np.empty(shape=a.shape[0])\n",
    "    for i in range(res.shape[0]):\n",
    "        res[i] = np.dot(a[i], b[i]) / np.linalg.norm(a[i]) / np.linalg.norm(b[i])\n",
    "    return res\n",
    "\n",
    "def top_n(sims, n=10):\n",
    "    \"\"\"\n",
    "    Receives a numpy array `sims` and finds the indices of the top `n` highest similarities.\n",
    "    The indices are returned in the ascending order (from lowest to highest index).\n",
    "    \"\"\"\n",
    "    # Source - https://stackoverflow.com/questions/6910641/how-do-i-get-indices-of-n-maximum-values-in-a-numpy-array\n",
    "    return np.argpartition(sims, -n)[-n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "N_train = len(train_batch.question1)\n",
    "N_test = len(test_batch.question1)\n",
    "\n",
    "train_s1_dim = train_batch.question1.shape[1]\n",
    "train_s2_dim = train_batch.question2.shape[1]\n",
    "test_s1_dim = test_batch.question1.shape[1]\n",
    "test_s2_dim = test_batch.question2.shape[1]\n",
    "\n",
    "question1_train = np.empty(shape=(N_train, train_s1_dim, 300))\n",
    "question2_train = np.empty(shape=(N_train, train_s2_dim, 300))\n",
    "question1_test = np.empty(shape=(N_test, test_s1_dim, 300))\n",
    "question2_test = np.empty(shape=(N_test, test_s2_dim, 300))\n",
    "\n",
    "question1_train_mean = np.empty(shape=(N_train, 300))\n",
    "question2_train_mean = np.empty(shape=(N_train, 300))\n",
    "question1_test_mean = np.empty(shape=(N_test, 300))\n",
    "question2_test_mean = np.empty(shape=(N_test, 300))\n",
    "\n",
    "for i in range(N_train):\n",
    "    s1_arr = np.array([embeddings[x] for x in train_batch.question1[i]])\n",
    "    s2_arr = np.array([embeddings[x] for x in train_batch.question2[i]])\n",
    "    question1_train[i] = s1_arr\n",
    "    question2_train[i] = s2_arr\n",
    "    question1_train_mean[i] = np.mean(s1_arr, axis=0)\n",
    "    question2_train_mean[i] = np.mean(s2_arr, axis=0)\n",
    "for i in range(N_test):\n",
    "    s1_arr = np.array([embeddings[x] for x in test_batch.question1[i]])\n",
    "    s2_arr = np.array([embeddings[x] for x in test_batch.question2[i]])\n",
    "    question1_test[i] = s1_arr\n",
    "    question2_test[i] = s2_arr\n",
    "    question1_test_mean[i] = np.mean(s1_arr, axis=0)\n",
    "    question2_test_mean[i] = np.mean(s2_arr, axis=0)\n",
    "\n",
    "# for i, si in enumerate(reversed(top_n(cosine_similarity(question1_train_mean, question2_train_mean), n=10))):\n",
    "#     row = train_df.iloc[si]\n",
    "#     print(f\"{i+1})\\n {row['question1']}\\n {row['question2']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layer_shape):\n",
    "        self.fc1 = nn.Linear(input_size, hidden_layer_shape[0])\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_layer_shape[1], 1)\n",
    "        self.softmax = nn.Softmax()\n",
    "    def forward(self, x):\n",
    "        hidden = self.relu(self.fc1(x))\n",
    "        output = self.fc2(hidden)\n",
    "        return self.softmax(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank('en_core_web_lg')\n",
    "nlp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
